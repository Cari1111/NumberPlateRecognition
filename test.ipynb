{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch with cuda\n",
    "# %pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Load a model\n",
    "# model = YOLO(\"best.onnx\")\n",
    "yolo_model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "path = os.path.join(os.path.abspath(\".\"),\"License Plate Recognition.v6i.yolov11.zip\")\n",
    "\n",
    "# # Train the model\n",
    "# train_results = model.train(\n",
    "#     data=path,  # path to dataset YAML\n",
    "#     epochs=100,  # number of training epochs\n",
    "#     # workers=100,\n",
    "#     # patience=20,\n",
    "#     imgsz=640,  # training image size\n",
    "#     device=\"cuda\" if torch.cuda.is_available() else \"cpu\",  # device to run on, i.e. device=0 or device=0,1,2,3 or device=cpu\n",
    "# )\n",
    "\n",
    "# # Evaluate model performance on the validation set\n",
    "# metrics = model.val()\n",
    "\n",
    "# # Export the model to ONNX format\n",
    "# path = model.export(format=\"onnx\")  # return path to exported model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.engine.results import Boxes, Results\n",
    "import os\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from safe_video import NumberPlateRecognition\n",
    "\n",
    "yolo_model_path = os.path.join(os.path.abspath(\".\"), \"models\", \"yolo11n.pt\")\n",
    "yolo_model = YOLO(yolo_model_path, task='detect')\n",
    "\n",
    "rec = NumberPlateRecognition()\n",
    "# image = cv2.imread(\"test2.png\")\n",
    "\n",
    "# image = image[:, :, ::-1]\n",
    "# box, conf, _, _ = rec.chained_detection(image, \"car\").tuple()\n",
    "# result = rec.blur_image(image, box)\n",
    "# plt.imshow(result)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_width = 1200\n",
    "display_height = 800\n",
    "\n",
    "cap = cv2.VideoCapture(\"exampleVideo.mp4\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if success:\n",
    "        results = yolo_model.track(frame, persist=True) # yolo_model(frame, imgsz=320 ,verbose = False)\n",
    "        # display(results[0].boxes)\n",
    "        #annotated_frames = results[0].plot() if results[0] is not None else frame \n",
    "        boxes = results[0].boxes if results[0] is not None else Boxes()\n",
    "        if boxes:\n",
    "            for box in boxes.data:\n",
    "                x1, y1, x2, y2 = map(int, box[:4])  \n",
    "                conf = box[5]\n",
    "                cls = int(box[6])\n",
    "                cropeed_image = frame[y1:y2, x1:x2]\n",
    "                \n",
    "                if conf > 0.5:  \n",
    "                    box, conf, _, _ = rec.chained_detection(cropeed_image, \"car\").tuple()\n",
    "                    result = rec.blur_image(cropeed_image, box)\n",
    "                    frame[y1:y2, x1:x2] = result\n",
    "                    \n",
    "        resized_frame = cv2.resize(frame, (display_width, display_height))\n",
    "        cv2.imshow(\"Tracking\", resized_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "                \n",
    "                \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NumberPlateRecognition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
